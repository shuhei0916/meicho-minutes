"""
ASSå­—å¹•ç”Ÿæˆå™¨
VoiceVoxã®audio_queryã‹ã‚‰ç²¾å¯†ãªã‚¿ã‚¤ãƒŸãƒ³ã‚°æƒ…å ±ã‚’æŠ½å‡ºã—ã¦ASSå­—å¹•ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆ
"""

import math
from typing import List, Dict, Any, Tuple, Optional
from dataclasses import dataclass


@dataclass
class MoraTiming:
    """ãƒ¢ãƒ¼ãƒ©ã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°æƒ…å ±"""
    text: str
    start_time: float
    end_time: float
    consonant_length: float
    vowel_length: float
    pitch: float


@dataclass  
class SubtitleChunk:
    """å­—å¹•ãƒãƒ£ãƒ³ã‚¯ã®æƒ…å ±"""
    text: str
    start_time: float
    end_time: float
    moras: List[MoraTiming]


class ASSSubtitleGenerator:
    """VoiceVoxã®audio_queryã‹ã‚‰é«˜ç²¾åº¦ASSå­—å¹•ã‚’ç”Ÿæˆ"""
    
    def __init__(self):
        """ASSå­—å¹•ç”Ÿæˆå™¨ã‚’åˆæœŸåŒ–"""
        # ãƒãƒ£ãƒ³ã‚¯åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.max_chars_per_chunk = 20         # 1ãƒãƒ£ãƒ³ã‚¯ã®æœ€å¤§æ–‡å­—æ•°
        self.max_duration_per_chunk = 3.0     # 1ãƒãƒ£ãƒ³ã‚¯ã®æœ€å¤§æ™‚é–“ï¼ˆç§’ï¼‰
        self.min_chunk_duration = 0.5        # 1ãƒãƒ£ãƒ³ã‚¯ã®æœ€å°æ™‚é–“ï¼ˆç§’ï¼‰
        
        # çµåˆåˆ¤å®šç”¨ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        self.connection_particles = ['ã®', 'ã«', 'ã‚’', 'ãŒ', 'ã¯', 'ã§', 'ã¨', 'ã‚„', 'ã‹']
        self.pause_punctuation = ['ã€‚', 'ï¼', 'ï¼Ÿ', 'ã€']
        
    def extract_mora_timings(self, accent_phrases: List[Dict], original_text: str = "") -> List[MoraTiming]:
        """
        VoiceVoxã®accent_phrasesã‹ã‚‰ãƒ¢ãƒ¼ãƒ©ã‚¿ã‚¤ãƒŸãƒ³ã‚°æƒ…å ±ã‚’æŠ½å‡º
        
        Args:
            accent_phrases: VoiceVoxã®audio_queryã‹ã‚‰å–å¾—ã—ãŸaccent_phrases
            
        Returns:
            ãƒ¢ãƒ¼ãƒ©ã‚¿ã‚¤ãƒŸãƒ³ã‚°æƒ…å ±ã®ãƒªã‚¹ãƒˆ
        """
        mora_timings = []
        cumulative_time = 0.0
        
        for phrase in accent_phrases:
            # é€šå¸¸ã®ãƒ¢ãƒ¼ãƒ©ã‚’å‡¦ç†
            for mora in phrase.get('moras', []):
                consonant_length = mora.get('consonant_length', 0.0) or 0.0
                vowel_length = mora.get('vowel_length', 0.0) or 0.0
                
                start_time = cumulative_time
                end_time = start_time + consonant_length + vowel_length
                
                mora_timing = MoraTiming(
                    text=mora.get('text', ''),
                    start_time=start_time,
                    end_time=end_time,
                    consonant_length=consonant_length,
                    vowel_length=vowel_length,
                    pitch=mora.get('pitch', 0.0)
                )
                
                mora_timings.append(mora_timing)
                cumulative_time = end_time
            
            # ãƒãƒ¼ã‚ºãƒ¢ãƒ¼ãƒ©ã‚’å‡¦ç†
            pause_mora = phrase.get('pause_mora')
            if pause_mora:
                consonant_length = pause_mora.get('consonant_length', 0.0) or 0.0
                vowel_length = pause_mora.get('vowel_length', 0.0) or 0.0
                
                if consonant_length > 0 or vowel_length > 0:
                    start_time = cumulative_time
                    end_time = start_time + consonant_length + vowel_length
                    
                    pause_timing = MoraTiming(
                        text='',  # ãƒãƒ¼ã‚ºã¯ç©ºæ–‡å­—
                        start_time=start_time,
                        end_time=end_time,
                        consonant_length=consonant_length,
                        vowel_length=vowel_length,
                        pitch=pause_mora.get('pitch', 0.0)
                    )
                    
                    mora_timings.append(pause_timing)
                    cumulative_time = end_time
        
        return mora_timings
    
    def create_subtitle_chunks(self, mora_timings: List[MoraTiming]) -> List[SubtitleChunk]:
        """
        ãƒ¢ãƒ¼ãƒ©ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã‹ã‚‰é©åˆ‡ãªå­—å¹•ãƒãƒ£ãƒ³ã‚¯ã‚’ä½œæˆ
        
        Args:
            mora_timings: ãƒ¢ãƒ¼ãƒ©ã‚¿ã‚¤ãƒŸãƒ³ã‚°æƒ…å ±ã®ãƒªã‚¹ãƒˆ
            
        Returns:
            å­—å¹•ãƒãƒ£ãƒ³ã‚¯ã®ãƒªã‚¹ãƒˆ
        """
        if not mora_timings:
            return []
        
        chunks = []
        current_chunk_moras = []
        current_text = ""
        
        for i, mora in enumerate(mora_timings):
            # ãƒãƒ¼ã‚ºã¯é£›ã°ã™ï¼ˆãƒ†ã‚­ã‚¹ãƒˆãªã—ï¼‰
            if not mora.text:
                continue
            
            # ç¾åœ¨ã®ãƒãƒ£ãƒ³ã‚¯ã«è¿½åŠ ã—ãŸå ´åˆã®åˆ¤å®š
            new_text = current_text + mora.text
            new_chunk_moras = current_chunk_moras + [mora]
            
            # ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²åˆ¤å®š
            should_split = self._should_split_chunk(
                current_text, new_text, current_chunk_moras, mora, i, mora_timings
            )
            
            if should_split and current_chunk_moras:
                # ç¾åœ¨ã®ãƒãƒ£ãƒ³ã‚¯ã‚’å®Œæˆã•ã›ã‚‹
                chunk = self._create_chunk_from_moras(current_chunk_moras, current_text)
                chunks.append(chunk)
                
                # æ–°ã—ã„ãƒãƒ£ãƒ³ã‚¯ã‚’é–‹å§‹
                current_chunk_moras = [mora]
                current_text = mora.text
            else:
                # ç¾åœ¨ã®ãƒãƒ£ãƒ³ã‚¯ã«è¿½åŠ 
                current_chunk_moras = new_chunk_moras
                current_text = new_text
        
        # æœ€å¾Œã®ãƒãƒ£ãƒ³ã‚¯ã‚’è¿½åŠ 
        if current_chunk_moras:
            chunk = self._create_chunk_from_moras(current_chunk_moras, current_text)
            chunks.append(chunk)
        
        return self._optimize_chunks(chunks)
    
    def _should_split_chunk(
        self, 
        current_text: str, 
        new_text: str, 
        current_moras: List[MoraTiming],
        new_mora: MoraTiming,
        index: int,
        all_moras: List[MoraTiming]
    ) -> bool:
        """
        ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²åˆ¤å®š
        
        Args:
            current_text: ç¾åœ¨ã®ãƒãƒ£ãƒ³ã‚¯ãƒ†ã‚­ã‚¹ãƒˆ
            new_text: è¿½åŠ å¾Œã®ãƒ†ã‚­ã‚¹ãƒˆ
            current_moras: ç¾åœ¨ã®ãƒ¢ãƒ¼ãƒ©ãƒªã‚¹ãƒˆ
            new_mora: è¿½åŠ äºˆå®šã®ãƒ¢ãƒ¼ãƒ©
            index: ç¾åœ¨ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
            all_moras: å…¨ãƒ¢ãƒ¼ãƒ©ãƒªã‚¹ãƒˆ
            
        Returns:
            åˆ†å‰²ã™ã‚‹ã‹ã©ã†ã‹
        """
        # æœ€åˆã®ãƒ¢ãƒ¼ãƒ©ã¯åˆ†å‰²ã—ãªã„
        if not current_moras:
            return False
        
        # æ–‡å­—æ•°åˆ¶é™ãƒã‚§ãƒƒã‚¯
        if len(new_text) > self.max_chars_per_chunk:
            return True
        
        # æ™‚é–“åˆ¶é™ãƒã‚§ãƒƒã‚¯
        duration = new_mora.end_time - current_moras[0].start_time
        if duration > self.max_duration_per_chunk:
            return True
        
        # å¥èª­ç‚¹ã§ã®åˆ†å‰²
        if current_text and current_text[-1] in self.pause_punctuation:
            return True
        
        # æ¥ç¶šåŠ©è©ã§ã®çµåˆå„ªå…ˆï¼ˆåˆ†å‰²ã‚’é¿ã‘ã‚‹ï¼‰
        if new_mora.text in self.connection_particles:
            return False
        
        # è‡ªç„¶ãªåŒºåˆ‡ã‚Šã§ã®åˆ†å‰²ï¼ˆåŠ©è©ã®å¾Œãªã©ï¼‰
        if (current_text and 
            current_text[-1] in self.connection_particles and 
            len(current_text) >= 3):  # æœ€å°é•·ã‚’ç¢ºä¿
            return True
        
        return False
    
    def _create_chunk_from_moras(self, moras: List[MoraTiming], text: str) -> SubtitleChunk:
        """ãƒ¢ãƒ¼ãƒ©ãƒªã‚¹ãƒˆã‹ã‚‰ãƒãƒ£ãƒ³ã‚¯ã‚’ä½œæˆ"""
        if not moras:
            return SubtitleChunk("", 0.0, 0.0, [])
        
        start_time = moras[0].start_time
        end_time = moras[-1].end_time
        
        return SubtitleChunk(
            text=text,
            start_time=start_time,
            end_time=end_time,
            moras=moras
        )
    
    def _optimize_chunks(self, chunks: List[SubtitleChunk]) -> List[SubtitleChunk]:
        """
        ãƒãƒ£ãƒ³ã‚¯ã‚’æœ€é©åŒ–ï¼ˆçŸ­ã™ãã‚‹ã‚‚ã®ã‚’çµåˆãªã©ï¼‰
        
        Args:
            chunks: æœ€é©åŒ–å‰ã®ãƒãƒ£ãƒ³ã‚¯ãƒªã‚¹ãƒˆ
            
        Returns:
            æœ€é©åŒ–å¾Œã®ãƒãƒ£ãƒ³ã‚¯ãƒªã‚¹ãƒˆ
        """
        if not chunks:
            return chunks
        
        optimized = []
        i = 0
        
        while i < len(chunks):
            current_chunk = chunks[i]
            duration = current_chunk.end_time - current_chunk.start_time
            
            # çŸ­ã™ãã‚‹ãƒãƒ£ãƒ³ã‚¯ã¯æ¬¡ã®ã‚‚ã®ã¨çµåˆ
            if (duration < self.min_chunk_duration and 
                i + 1 < len(chunks) and
                len(current_chunk.text) + len(chunks[i + 1].text) <= self.max_chars_per_chunk):
                
                next_chunk = chunks[i + 1]
                merged_chunk = SubtitleChunk(
                    text=current_chunk.text + next_chunk.text,
                    start_time=current_chunk.start_time,
                    end_time=next_chunk.end_time,
                    moras=current_chunk.moras + next_chunk.moras
                )
                optimized.append(merged_chunk)
                i += 2  # 2ã¤ã®ãƒãƒ£ãƒ³ã‚¯ã‚’ã‚¹ã‚­ãƒƒãƒ—
            else:
                optimized.append(current_chunk)
                i += 1
        
        return optimized
    
    def generate_ass_content(self, subtitle_chunks: List[SubtitleChunk], style_name: str = "Default") -> str:
        """
        å­—å¹•ãƒãƒ£ãƒ³ã‚¯ã‹ã‚‰ASSå½¢å¼ã®æ–‡å­—åˆ—ã‚’ç”Ÿæˆ
        
        Args:
            subtitle_chunks: å­—å¹•ãƒãƒ£ãƒ³ã‚¯ã®ãƒªã‚¹ãƒˆ
            style_name: ASS ã‚¹ã‚¿ã‚¤ãƒ«å
            
        Returns:
            ASSå½¢å¼ã®æ–‡å­—åˆ—
        """
        # ASSãƒ˜ãƒƒãƒ€ãƒ¼
        header = """[Script Info]
Title: VoiceVox Generated Subtitles
ScriptType: v4.00+
WrapStyle: 0
ScaledBorderAndShadow: yes
YCbCr Matrix: TV.601
PlayResX: 1920
PlayResY: 1080

[V4+ Styles]
Format: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding
Style: Default,Noto Sans CJK JP,64,&H00FFFFFF,&H000000FF,&H00000000,&H80000000,0,0,0,0,100,100,0,0,1,3,0,2,60,60,60,1

[Events]
Format: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text
"""
        
        # ãƒ€ã‚¤ã‚¢ãƒ­ã‚°è¡Œã‚’ç”Ÿæˆ
        dialogues = []
        for chunk in subtitle_chunks:
            start_time = self._format_ass_time(chunk.start_time)
            end_time = self._format_ass_time(chunk.end_time)
            text = chunk.text.replace('\n', '\\N')  # æ”¹è¡Œã‚’ASSå½¢å¼ã«ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—
            
            dialogue = f"Dialogue: 0,{start_time},{end_time},{style_name},,0,0,0,,{text}"
            dialogues.append(dialogue)
        
        return header + "\n".join(dialogues)
    
    def _format_ass_time(self, seconds: float) -> str:
        """
        ç§’ã‚’ASSæ™‚é–“å½¢å¼ï¼ˆH:MM:SS.CCï¼‰ã«å¤‰æ›
        
        Args:
            seconds: ç§’æ•°
            
        Returns:
            ASSæ™‚é–“å½¢å¼ã®æ–‡å­—åˆ—
        """
        total_centiseconds = int(seconds * 100)
        hours = total_centiseconds // 360000
        minutes = (total_centiseconds % 360000) // 6000
        secs = (total_centiseconds % 6000) // 100
        centiseconds = total_centiseconds % 100
        
        return f"{hours}:{minutes:02d}:{secs:02d}.{centiseconds:02d}"
    
    def create_subtitle_chunks_from_text_and_timings(
        self,
        original_text: str,
        mora_timings: List[MoraTiming]
    ) -> List[SubtitleChunk]:
        """
        å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆã¨ãƒ¢ãƒ¼ãƒ©ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã‹ã‚‰é©åˆ‡ãªå­—å¹•ãƒãƒ£ãƒ³ã‚¯ã‚’ä½œæˆ
        
        Args:
            original_text: å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆï¼ˆèª­ã‚ã‚‹å½¢ï¼‰
            mora_timings: ãƒ¢ãƒ¼ãƒ©ã‚¿ã‚¤ãƒŸãƒ³ã‚°æƒ…å ±
            
        Returns:
            å­—å¹•ãƒãƒ£ãƒ³ã‚¯ã®ãƒªã‚¹ãƒˆ
        """
        if not mora_timings:
            return []
        
        # ãƒ†ã‚­ã‚¹ãƒˆã‚’å¥èª­ç‚¹ã§å¤§ã¾ã‹ã«åˆ†å‰²
        sentences = []
        current_sentence = ""
        
        for char in original_text:
            current_sentence += char
            if char in self.pause_punctuation:
                sentences.append(current_sentence.strip())
                current_sentence = ""
        
        if current_sentence.strip():
            sentences.append(current_sentence.strip())
        
        # å„æ–‡ã«å¯¾ã—ã¦ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã‚’å‰²ã‚Šå½“ã¦
        chunks = []
        total_duration = mora_timings[-1].end_time if mora_timings else 0
        total_chars = len(original_text)
        current_time = 0.0
        
        for sentence in sentences:
            if not sentence:
                continue
            
            # ã“ã®æ–‡ã®æ¨å®šæ™‚é–“ã‚’è¨ˆç®—
            char_ratio = len(sentence) / total_chars if total_chars > 0 else 0
            estimated_duration = total_duration * char_ratio
            
            # é©åˆ‡ãªé•·ã•ã§ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²
            if len(sentence) <= self.max_chars_per_chunk:
                # ãã®ã¾ã¾1ãƒãƒ£ãƒ³ã‚¯ã«
                chunks.append(SubtitleChunk(
                    text=sentence,
                    start_time=current_time,
                    end_time=current_time + estimated_duration,
                    moras=[]
                ))
                current_time += estimated_duration + 0.2  # å°‘ã—é–“éš”ã‚’ç©ºã‘ã‚‹
            else:
                # é•·ã„æ–‡ã¯åˆ†å‰²
                words = sentence
                chunk_size = self.max_chars_per_chunk
                for i in range(0, len(words), chunk_size):
                    chunk_text = words[i:i + chunk_size]
                    chunk_duration = estimated_duration * len(chunk_text) / len(sentence)
                    
                    chunks.append(SubtitleChunk(
                        text=chunk_text,
                        start_time=current_time,
                        end_time=current_time + chunk_duration,
                        moras=[]
                    ))
                    current_time += chunk_duration + 0.1
        
        return chunks
    
    def generate_ass_from_accent_phrases(
        self, 
        accent_phrases: List[Dict], 
        output_path: str = None,
        original_text: str = ""
    ) -> str:
        """
        VoiceVoxã®accent_phrasesã‹ã‚‰ç›´æ¥ASSå­—å¹•ã‚’ç”Ÿæˆ
        
        Args:
            accent_phrases: VoiceVoxã®audio_queryã‹ã‚‰å–å¾—ã—ãŸaccent_phrases
            output_path: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆNoneã®å ´åˆã¯æ–‡å­—åˆ—ã®ã¿è¿”ã™ï¼‰
            original_text: å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆï¼ˆèª­ã‚ã‚‹å½¢ï¼‰
            
        Returns:
            ASSå½¢å¼ã®æ–‡å­—åˆ—
        """
        # ãƒ¢ãƒ¼ãƒ©ã‚¿ã‚¤ãƒŸãƒ³ã‚°æŠ½å‡º
        mora_timings = self.extract_mora_timings(accent_phrases, original_text)
        
        # å­—å¹•ãƒãƒ£ãƒ³ã‚¯ä½œæˆ
        if original_text:
            # å…ƒãƒ†ã‚­ã‚¹ãƒˆãŒã‚ã‚‹å ´åˆã¯ã€ãã‚Œã‚’åŸºã«ãƒãƒ£ãƒ³ã‚¯ä½œæˆ
            subtitle_chunks = self.create_subtitle_chunks_from_text_and_timings(
                original_text, mora_timings
            )
        else:
            # å¾“æ¥ã®æ–¹æ³•ï¼ˆãƒ¢ãƒ¼ãƒ©ãƒ™ãƒ¼ã‚¹ï¼‰
            subtitle_chunks = self.create_subtitle_chunks(mora_timings)
        
        # ASSå½¢å¼ç”Ÿæˆ
        ass_content = self.generate_ass_content(subtitle_chunks)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›ï¼ˆæŒ‡å®šã•ã‚ŒãŸå ´åˆï¼‰
        if output_path:
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(ass_content)
        
        return ass_content


if __name__ == "__main__":
    import argparse
    import json
    import sys
    from pathlib import Path
    
    parser = argparse.ArgumentParser(
        description='ASSå­—å¹•ç”Ÿæˆå™¨ - VoiceVox audio_queryã‹ã‚‰ASSå­—å¹•ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆ'
    )
    
    parser.add_argument('--audio-query', type=str, required=True, 
                        help='VoiceVox audio_queryã®JSONãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹')
    parser.add_argument('--output', type=str, required=True, 
                        help='å‡ºåŠ›ASSãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹')
    
    args = parser.parse_args()
    
    try:
        # audio_query JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
        if not Path(args.audio_query).exists():
            print(f"âŒ ã‚¨ãƒ©ãƒ¼: audio_queryãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {args.audio_query}", file=sys.stderr)
            sys.exit(1)
        
        with open(args.audio_query, 'r', encoding='utf-8') as f:
            audio_query_data = json.load(f)
        
        accent_phrases = audio_query_data.get('accent_phrases', [])
        if not accent_phrases:
            print("âŒ ã‚¨ãƒ©ãƒ¼: accent_phrasesãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“", file=sys.stderr)
            sys.exit(1)
        
        print(f"ğŸ“œ audio_queryèª­ã¿è¾¼ã¿: {args.audio_query}", file=sys.stderr)
        print(f"   ã‚¢ã‚¯ã‚»ãƒ³ãƒˆå¥æ•°: {len(accent_phrases)}", file=sys.stderr)
        
        # ASSå­—å¹•ç”Ÿæˆ
        generator = ASSSubtitleGenerator()
        ass_content = generator.generate_ass_from_accent_phrases(accent_phrases, args.output)
        
        print(f"âœ… ASSå­—å¹•ç”Ÿæˆå®Œäº†: {args.output}", file=sys.stderr)
        
        # çµ±è¨ˆæƒ…å ±è¡¨ç¤º
        lines = ass_content.split('\n')
        dialogue_lines = [line for line in lines if line.startswith('Dialogue:')]
        print(f"   å­—å¹•ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæ•°: {len(dialogue_lines)}", file=sys.stderr)
        
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}", file=sys.stderr)
        import traceback
        traceback.print_exc()
        sys.exit(1)